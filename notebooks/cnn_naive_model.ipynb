{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxE1w06_Uit5",
        "outputId": "2347f950-e368-4c51-b3f1-21c790ba18a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "print(\"Done!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_active_device():\n",
        "    \"\"\"Picking GPU if available or else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "active_device = get_active_device()\n",
        "print(active_device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAiIdr3IU2Gz",
        "outputId": "8af5773e-bd26-4be3-8a9a-c60cc6a36249"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration Parameters\n",
        "# A random sub sample of the LA data was used for this experiment.\n",
        "# The LA data was used following most of the academic literture,\n",
        "# which deals with this dataset.\n",
        "# The sub-sampling was done due to huge running times.\n",
        "# The dataset was split as follows:\n",
        "# Train Set - 80% (25k -> 20k)\n",
        "# Dev Set   - 40% (25k -> 10k)\n",
        "# Eval Set  - 14% (70k -> 10k)\n",
        "\n",
        "config = {\n",
        "    \"train_protocol\":\"drive/MyDrive/AntiSpoofing/sub_sample/train_protocol.txt\",\n",
        "    \"dev_protocol\":\"drive/MyDrive/AntiSpoofing/sub_sample/dev_protocol.txt\",\n",
        "    \"eval_protocol\":\"drive/MyDrive/AntiSpoofing/sub_sample/eval_protocol.txt\",\n",
        "    \"train_audio_folder\":\"drive/MyDrive/AntiSpoofing/sub_sample/train/\",\n",
        "    \"dev_audio_folder\":\"drive/MyDrive/AntiSpoofing/sub_sample/dev/\",\n",
        "    \"eval_audio_folder\":\"drive/MyDrive/AntiSpoofing/sub_sample/eval/\",\n",
        "    \"max_speech_length\":64600,\n",
        "    \"batch_size\": 32,\n",
        "    \"num_epochs\": 15,\n",
        "    \"min_valid_epochs\":3,\n",
        "    \"early_stop_max_no_imp\":3,\n",
        "    \"optimizer_func\":\"adadelta\",\n",
        "    \"learning_rate\":0.05,\n",
        "    \"rho\":0.95,\n",
        "    \"beta_one\":0,\n",
        "    \"beta_two\":0.98,\n",
        "    \"eps\":0.00000001,\n",
        "    \"fft_frame_size\":360,\n",
        "    \"hop_length\":120,\n",
        "    \"sample_rate\":16000,\n",
        "    \"lfcc_size\":256,\n",
        "    \"filter_size\":256,\n",
        "    \"kernels\":[3,4,5,6,7],\n",
        "    \"dropout\":0.5\n",
        "}\n"
      ],
      "metadata": {
        "id": "QcOH3VsYU-Lq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loading utilities\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "from torch import Tensor\n",
        "from torch.utils.data import Dataset\n",
        "import torchaudio\n",
        "\n",
        "## Adapted from \"Hemlata Tak, Jee-weon Jung - tak@eurecom.fr, jeeweon.jung@navercorp.com\"\n",
        "\n",
        "AUDIO_FILE_FIELD = 1\n",
        "ATTACK_TYPE_FIELD = 3\n",
        "LABEL_FIELD = 4\n",
        "LABELS_MAP = {\"bonafide\":1, \"spoof\":0}\n",
        "MAX_SPEECH_LENGTH = 64600\n",
        "\n",
        "def pad(x, max_len=64600):\n",
        "    x_len = x.shape[0]\n",
        "    if x_len >= max_len:\n",
        "        return x[:max_len]\n",
        "    # need to pad\n",
        "    num_repeats = int(max_len / x_len) + 1\n",
        "    padded_x = np.tile(x, (1, num_repeats))[:, :max_len][0]\n",
        "    return padded_x\n",
        "\n",
        "\n",
        "def pad_random(x: np.ndarray, max_len: int = 64600):\n",
        "    x_len = x.shape[0]\n",
        "    # if duration is already long enough\n",
        "    if x_len >= max_len:\n",
        "        stt = np.random.randint(x_len - max_len)\n",
        "        return x[stt:stt + max_len]\n",
        "\n",
        "    # if too short\n",
        "    num_repeats = int(max_len / x_len) + 1\n",
        "    padded_x = np.tile(x, (num_repeats))[:max_len]\n",
        "    return padded_x\n",
        "\n",
        "class Dataset_ASVspoof2019(Dataset):\n",
        "    def __init__(self, config: dict, sample_name: str):\n",
        "        # Read the data set protocol file.\n",
        "        protocol_file = config[sample_name + \"_protocol\"]\n",
        "        audio_files_folder = config[sample_name + \"_audio_folder\"]\n",
        "        with open(protocol_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            data_set_items = [x.strip().split() for x in f.readlines()]\n",
        "\n",
        "        self.max_speech_length = config['max_speech_length']\n",
        "        self.audio_files = [x[AUDIO_FILE_FIELD] for x in data_set_items]\n",
        "        self.labels = [LABELS_MAP[x[LABEL_FIELD]] for x in data_set_items]\n",
        "        self.audio_files_folder = audio_files_folder\n",
        "        self.speckwargs={\"n_fft\": config['fft_frame_size'], \"hop_length\": config['hop_length'], \"center\": False}\n",
        "        self.transform = torchaudio.transforms.LFCC(sample_rate=config['sample_rate'], n_lfcc=config['lfcc_size'], speckwargs=self.speckwargs)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.audio_files)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        audio_file = self.audio_files[index]\n",
        "        signal, _ = sf.read(self.audio_files_folder + audio_file + \".flac\")\n",
        "        padded_signal = pad_random(signal, self.max_speech_length)\n",
        "        tensor_signal = Tensor(padded_signal)\n",
        "        lfcc = self.transform(tensor_signal)\n",
        "        y = self.labels[index]\n",
        "        return lfcc, y\n"
      ],
      "metadata": {
        "id": "FyMP_11JVNtr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data example.\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "ds = Dataset_ASVspoof2019(config, \"train\")\n",
        "dl = DataLoader(ds, batch_size=config['batch_size'], shuffle=True, drop_last=False, pin_memory=True)\n",
        "\n",
        "print(\"DataSet:\")\n",
        "print(\"#Items: \" + str(len(ds)))\n",
        "for signal, label in ds:\n",
        "    break\n",
        "\n",
        "print(\"Signal:\")\n",
        "print(signal.shape)\n",
        "print(signal[:5,:5])\n",
        "print(\"Label: \" + str(label))\n",
        "\n",
        "print(\"\\nDataLoader:\")\n",
        "print(\"#Items: \" + str(len(dl)))\n",
        "for batch, label in dl:\n",
        "    break\n",
        "\n",
        "print(\"batch: \" + str(batch.shape))\n",
        "print(\"labels: \" + str(label[:10]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqpUSUqTVn5N",
        "outputId": "aedd6393-4c73-40d1-b07c-a7273931c016"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataSet:\n",
            "#Items: 20288\n",
            "Signal:\n",
            "torch.Size([256, 536])\n",
            "tensor([[-515.9557, -515.7926, -516.3044, -516.5004, -518.4332],\n",
            "        [   6.9788,    7.2079,    6.4883,    6.2107,    3.4784],\n",
            "        [   6.9575,    7.1820,    6.4748,    6.1960,    3.4668],\n",
            "        [   6.9223,    7.1391,    6.4525,    6.1716,    3.4476],\n",
            "        [   6.8731,    7.0793,    6.4213,    6.1375,    3.4209]])\n",
            "Label: 1\n",
            "\n",
            "DataLoader:\n",
            "#Items: 634\n",
            "batch: torch.Size([32, 256, 536])\n",
            "labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The CNN Model.\n",
        "# This model was inspired by the paper:\n",
        "#\n",
        "# Siamese Convolutional Neural Network\n",
        "# Using Gaussian Probability Feature for\n",
        "# Spoofing Speech Detection\n",
        "#\n",
        "# of Zhenchun Lei, 2020.\n",
        "#\n",
        "# In the paper, though, they converted the lfcc vectors\n",
        "# into GMM vectors, which obtained very good results.\n",
        "# Due to resources scarcity I content with the lfcc vectors.\n",
        "#\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 config: dict,\n",
        "                 num_classes):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        print('allocate convolution  layers')\n",
        "        filter_width = config['filter_size']\n",
        "        kernels = config['kernels']\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv1d(in_channels=config['lfcc_size'],\n",
        "                      out_channels=filter_width,\n",
        "                      kernel_size=kernel)\n",
        "            for kernel in kernels\n",
        "        ])\n",
        "\n",
        "        self.fc = nn.Linear(filter_width * len(kernels), num_classes)\n",
        "        self.dropout = nn.Dropout(p=config['dropout'])\n",
        "\n",
        "    def forward(self, signals):\n",
        "        # signals = [#batch size, lfcc dim, speech length]\n",
        "\n",
        "        x_conv_list = [F.relu(conv(signals)) for conv in self.convs]\n",
        "        # x_conv = [batch size, out_channel_width, speech length - kernel size + 1]\n",
        "        \n",
        "        x_pool_list = [F.max_pool1d(x_conv, kernel_size=x_conv.shape[2]) for x_conv in x_conv_list]\n",
        "        # x_pool = [batch size, out_channel_width, 1]\n",
        "        \n",
        "        x_fc = torch.cat([x_pool.squeeze(dim=2) for x_pool in x_pool_list], dim=1)\n",
        "        # x_fc = [batch size, out_channel_width * #kernels]\n",
        "        \n",
        "        logits = self.fc(self.dropout(x_fc))\n",
        "        # logits = [batch size, #classes]\n",
        "        \n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "R9hI6yZwYBrq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EER computation function\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "from sklearn import metrics\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def compute_eer(model: torch.nn.Module, test_set: DataLoader) -> tuple:\n",
        "    t0 = time.time()\n",
        "    active_device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
        "    model.eval()\n",
        "    scores = []\n",
        "    targets = []\n",
        "    for signals, labels in test_set:\n",
        "        signals = signals.to(active_device)\n",
        "        labels = labels.to(active_device)\n",
        "        with torch.no_grad():\n",
        "            logits = model(signals)\n",
        "        curr_scores = torch.softmax(logits, dim=1)\n",
        "        curr_scores = curr_scores.detach().cpu().numpy()\n",
        "        curr_scores = curr_scores[:,1] - curr_scores[:,0]\n",
        "        curr_scores = curr_scores.clip(min=0)\n",
        "\n",
        "        scores.append(curr_scores)\n",
        "        targets.append(labels.detach().cpu().numpy())\n",
        "\n",
        "    scores = np.concatenate(scores, axis=0)\n",
        "    targets = np.concatenate(targets, axis=0)\n",
        "    fpr, tpr, _ = metrics.roc_curve(targets, scores)\n",
        "    fnr = 1 - tpr\n",
        "    eer_index = np.nanargmin(np.absolute(fpr - fnr))\n",
        "        \n",
        "    return np.mean((fpr[eer_index], fnr[eer_index]))*100, (time.time() - t0)"
      ],
      "metadata": {
        "id": "4VyY0gE-ZHXr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def get_optimizer(parameters, config: dict):\n",
        "    optimizer = None\n",
        "    opt_name = config['optimizer_func']\n",
        "    if opt_name == \"adadelta\":\n",
        "        optimizer = optim.Adadelta(parameters,\n",
        "                                   lr=config['learning_rate'],\n",
        "                                   rho=config['rho'])\n",
        "    elif opt_name == 'sgd':\n",
        "        optimizer = optim.SGD(parameters, config['learning_rate'])\n",
        "    elif opt_name == \"adam\":\n",
        "        optimizer = optim.Adam(parameters,\n",
        "                               lr=config['learning_rate'],\n",
        "                               betas=(config['beta_one'],config['beta_two'],),\n",
        "                               eps=config['eps'])\n",
        "    else:\n",
        "        print('Wrong optimizer name: ' + opt_name)\n",
        "        \n",
        "    return optimizer\n"
      ],
      "metadata": {
        "id": "gku31XifZ3ry"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "import copy\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "DEFAULT_MAX_EER = 1000\n",
        "SEED = 42\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self):\n",
        "        self.active_device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
        "\n",
        "    def train(self, config: dict) -> tuple:\n",
        "        print('CNN trainer - start')\n",
        "\n",
        "        pending_model = CNN(config, 2)\n",
        "        pending_model = pending_model.to(self.active_device)\n",
        "        optimal_model = None\n",
        "\n",
        "        print(\"Load samples\")\n",
        "        train_dataset = Dataset_ASVspoof2019(config, \"train\")\n",
        "        dev_dataset = Dataset_ASVspoof2019(config, \"dev\")\n",
        "        eval_dataset = Dataset_ASVspoof2019(config, \"eval\")\n",
        "\n",
        "        train_loader = DataLoader(train_dataset,\n",
        "                                  batch_size=config['batch_size'],\n",
        "                                  shuffle=True,\n",
        "                                  drop_last=True)\n",
        "        \n",
        "        dev_loader = DataLoader(dev_dataset,\n",
        "                                batch_size=config['batch_size'],\n",
        "                                shuffle=False,\n",
        "                                drop_last=False)\n",
        "        \n",
        "        eval_loader = DataLoader(eval_dataset,\n",
        "                                 batch_size=config['batch_size'],\n",
        "                                 shuffle=False,\n",
        "                                 drop_last=False)\n",
        "\n",
        "        \n",
        "        print('set optimizer & loss')\n",
        "        optimizer = get_optimizer(pending_model.parameters(), config)\n",
        "        weight = torch.FloatTensor([0.1, 0.9]).to(self.active_device)\n",
        "        criterion = torch.nn.CrossEntropyLoss(weight=weight)\n",
        "\n",
        "        best_dev_eer = DEFAULT_MAX_EER\n",
        "        best_dev_epoch = -1\n",
        "        best_eval_eer = DEFAULT_MAX_EER\n",
        "        best_eval_epoch = -1\n",
        "        \n",
        "        print('start training loops. #epochs = ' + str(config['num_epochs']))\n",
        "        print(f\"{'Epoch':^7} | {'Train Loss':^12} | {'Train EER':^11} | {'Dev EER':^10} | {'Eval EER':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*50)              \n",
        "        \n",
        "        min_loss = 100\n",
        "        num_no_imp = 0\n",
        "        for i in range(config['num_epochs']):\n",
        "            epoch = i + 1\n",
        "            epoch_start_time = time.time()\n",
        "            total_loss = 0\n",
        "            num_batches = 0\n",
        "            \n",
        "            pending_model.train()\n",
        "            for signals, labels in train_loader:\n",
        "                signals = signals.to(self.active_device)\n",
        "                labels = labels.to(self.active_device)\n",
        "                logits = pending_model(signals)\n",
        "                \n",
        "                optimizer.zero_grad()\n",
        "                loss = criterion(logits, labels)\n",
        "                total_loss += loss.item()\n",
        "                num_batches += 1\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                \n",
        "            avg_loss = total_loss / num_batches\n",
        "            epoch_time = time.time() - epoch_start_time\n",
        "            \n",
        "            # Validation test.\n",
        "            dev_eer, _ = compute_eer(pending_model, dev_loader)\n",
        "            train_eer, _ = compute_eer(pending_model, train_loader)\n",
        "            eval_eer, _ = compute_eer(pending_model, eval_loader)\n",
        "            print(f\"{epoch:^7} | {avg_loss:^12.6f} | {train_eer:^9.2f} | {dev_eer:^9.2f} |  {eval_eer:^9.4f} | {epoch_time:^9.2f}\")\n",
        "                \n",
        "            if avg_loss < min_loss:\n",
        "                min_loss = avg_loss\n",
        "                num_no_imp = 0\n",
        "            else:\n",
        "                num_no_imp += 1\n",
        "                \n",
        "            if num_no_imp > config[\"early_stop_max_no_imp\"]:\n",
        "                print('early stop exit')\n",
        "                break\n",
        "            \n",
        "            if epoch < config[\"min_valid_epochs\"]:\n",
        "                continue\n",
        "            \n",
        "            if dev_eer < best_dev_eer:\n",
        "                best_dev_eer = dev_eer\n",
        "                best_dev_epoch = epoch\n",
        "                optimal_model = copy.deepcopy(pending_model)\n",
        "\n",
        "            if eval_eer < best_eval_eer:\n",
        "                best_eval_eer = eval_eer\n",
        "                best_eval_epoch = epoch\n",
        "        \n",
        "        print('AASIST trainer - end\\n')\n",
        "        print(\"Best Dev EER = {:.2f}\".format(best_dev_eer) + \", best epoch = \" + str(best_dev_epoch))\n",
        "        print(\"Best Eval Acc = {:.2f}\".format(best_eval_eer) + \", best epoch = \" + str(best_eval_epoch))\n",
        "        return pending_model, optimal_model, best_dev_epoch\n"
      ],
      "metadata": {
        "id": "MX7rbCtXZYca"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer()\n",
        "last_epoch_model, best_dev_eer_model, best_dev_eer_epoch = trainer.train(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ki2DrcvaDDp",
        "outputId": "1bbebf8d-b489-4362-ebec-9526886d0a10"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN trainer - start\n",
            "allocate convolution  layers\n",
            "Load samples\n",
            "set optimizer & loss\n",
            "start training loops. #epochs = 15\n",
            " Epoch  |  Train Loss  |  Train EER  |  Dev EER   | Eval EER  |  Elapsed \n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}